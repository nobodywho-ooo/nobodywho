## What is NobodyWho?

NobodyWho is a lightweight, open-source AI engine for local LLM inference. <br/>
We provide a simple, privacy forward way of interacting with LLMs with no infrastructure needed!

In short, if you want to run a LLM, and integrate it with [tools](./tool-calling.md), configure its output,
enable real-time streaming of tokens, or maybe use it for creation of embeddings, NobodyWho makes it easy.

All of this is enabled by [Llama.cpp](https://github.com/ggml-org/llama.cpp), while having nice, simple Python API.

No need to mess around with docker containers, GPU servers, API keys, etc. We make it easy to run local LMMs in python and Godot with more integrations coming soon!

## Code documentation 
If you are already familiar with the basics of LLMs we suggest you go straight to the documentation of your selected integration. 
- [Godot](godot/index.md)
- [Python](python/index.md)

## Basic LLM concepts

If are unfamiliar with the basics of LLMs or are just intestered we also provide a simple introduction to the most important concepts you need to know in order to get the most out of NobodyWho. 